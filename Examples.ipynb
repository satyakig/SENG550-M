{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = [1, 2, 3]\n",
    "arr2 = [4, 5, 6, 1, 2]\n",
    "\n",
    "art1 = [('a', 1), ('b', 2), ('c', 3)]\n",
    "art2 = [('a', 10), ('f', 6), ('e', 5), ('d', 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 4, 5, 6]\n",
      "[4, 6, 2]\n",
      "[[4, 40], [5, 50], [6, 60], [1, 10], [2, 20]]\n",
      "[4, 40, 5, 50, 6, 60, 1, 10, 2, 20]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize(arr1)\n",
    "rdd2 = sc.parallelize(arr2)\n",
    "\n",
    "print(rdd2.distinct().collect())\n",
    "print(rdd2.filter(lambda x: x % 2 == 0).collect())\n",
    "print(rdd2.map(lambda x: [x, x * 10]).collect())\n",
    "print(rdd2.flatMap(lambda x: [x, x * 10]).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 1, 2]\n",
      "[1, 2]\n",
      "[(1, 4), (1, 5), (1, 6), (1, 1), (1, 2), (2, 4), (2, 5), (2, 6), (2, 1), (2, 2), (3, 4), (3, 5), (3, 6), (3, 1), (3, 2)]\n"
     ]
    }
   ],
   "source": [
    "print(rdd1.union(rdd2).collect())\n",
    "print(rdd1.intersection(rdd2).collect())\n",
    "print(rdd1.cartesian(rdd2).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', (1, 10))]\n",
      "[('a', (1, 10)), ('b', (2, None)), ('c', (3, None))]\n",
      "[('a', (1, 10)), ('d', (None, 4)), ('e', (None, 5)), ('f', (None, 6))]\n",
      "[('a', (1, 10)), ('b', (2, None)), ('c', (3, None)), ('d', (None, 4)), ('e', (None, 5)), ('f', (None, 6))]\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize(art1)\n",
    "rdd2 = sc.parallelize(art2)\n",
    "\n",
    "print(rdd1.join(rdd2).sortByKey().collect())\n",
    "print(rdd1.leftOuterJoin(rdd2).sortByKey().collect())\n",
    "print(rdd1.rightOuterJoin(rdd2).sortByKey().collect())\n",
    "print(rdd1.fullOuterJoin(rdd2).sortByKey().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "x = rdd1.reduce(lambda a, b: ('', a[1] + b[1]))\n",
    "print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('b', 20), ('b', None), ('c', 30), ('c', None), ('f', None), ('f', 60), ('a', 10), ('a', 100), ('e', None), ('e', 50), ('d', None), ('d', 40), ('b', None), ('b', 20), ('c', None), ('c', 30), ('f', 60), ('f', None), ('a', 100), ('a', 10), ('e', 50), ('e', None), ('d', 40), ('d', None)]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "bigRdd1 = rdd1.fullOuterJoin(rdd2).flatMap(lambda x: [(x[0], val) for val in x[1]])\n",
    "bigRdd2 = rdd2.fullOuterJoin(rdd1).flatMap(lambda x: [(x[0], val) for val in x[1]])\n",
    "bigRdd = bigRdd1.union(bigRdd2)\n",
    "\n",
    "bigRddArr = bigRdd.collect()\n",
    "\n",
    "broad = sc.broadcast(10)\n",
    "acc = sc.accumulator(0)\n",
    "\n",
    "def mapyo(x):\n",
    "    val = x[1]\n",
    "    \n",
    "    if val is None:\n",
    "        acc.add(1)\n",
    "    else:\n",
    "        val *= broad.value\n",
    "    \n",
    "    return (x[0], val)\n",
    "\n",
    "res = bigRdd.map(mapyo)\n",
    "print(res.collect())\n",
    "print(acc.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ab', ['c', 'd']),\n",
       " ('ac', ['b', 'd']),\n",
       " ('ad', ['b', 'c']),\n",
       " ('bc', ['a', 'd']),\n",
       " ('bd', ['a', 'c']),\n",
       " ('be', []),\n",
       " ('cd', ['a', 'b'])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "friends = [\n",
    "    ('a', ['b', 'c', 'd']), \n",
    "    ('b', ['a', 'c', 'd', 'e']), \n",
    "    ('c', ['a', 'b', 'd']), \n",
    "    ('d', ['a', 'b', 'c']), \n",
    "    ('e', ['b']), \n",
    "]\n",
    "\n",
    "rdd = sc.parallelize(friends)\n",
    "\n",
    "def map_stage(x):\n",
    "    friend_x = x[0]\n",
    "    friends = x[1]\n",
    "    arr = []\n",
    "    \n",
    "    for friend in friends:       \n",
    "        key = friend_x + friend if friend_x < friend else friend + friend_x\n",
    "        arr.append((key, [x for x in friends if x != friend]))\n",
    "        \n",
    "    return arr\n",
    "\n",
    "mutuals = rdd.flatMap(map_stage).reduceByKey(lambda a, b: list(set(a) & set(b))).sortByKey()\n",
    "display(mutuals.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
